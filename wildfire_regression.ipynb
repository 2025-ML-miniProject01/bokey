{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### 시각화 라이브러리 정의\n",
    "# - 파이썬에서 사용되는 기본 시각화 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# - 히트맵 라이브러리\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "import os\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dask_ml.wrappers import Incremental\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn import set_config\n",
    "import joblib  # 모델 저장용\n",
    "\n",
    "from model_class import Models\n",
    "\n",
    "\n",
    "### 한글처리\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")\n",
    "\n",
    "# - 마이너스 기호 깨짐 처리\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 906078 entries, 0 to 906077\n",
      "Data columns (total 29 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   latitude               906078 non-null  float64\n",
      " 1   longitude              906078 non-null  float64\n",
      " 2   brightness             900596 non-null  float64\n",
      " 3   bright_t31             900596 non-null  float64\n",
      " 4   frp                    900596 non-null  float64\n",
      " 5   T2M                    900596 non-null  float64\n",
      " 6   WS2M                   900596 non-null  float64\n",
      " 7   RH2M                   900596 non-null  float64\n",
      " 8   PRECTOTCORR            900596 non-null  float64\n",
      " 9   confidence_h           900596 non-null  float64\n",
      " 10  confidence_l           900596 non-null  float64\n",
      " 11  confidence_n           900596 non-null  float64\n",
      " 12  daynight_D             900596 non-null  float64\n",
      " 13  daynight_N             900596 non-null  float64\n",
      " 14  year                   900596 non-null  float64\n",
      " 15  month                  900596 non-null  float64\n",
      " 16  day                    900596 non-null  float64\n",
      " 17  season                 900596 non-null  float64\n",
      " 18  weekday                900596 non-null  float64\n",
      " 19  WS2M_RH2M_interaction  900596 non-null  float64\n",
      " 20  high_temperature       900596 non-null  float64\n",
      " 21  precipitation_flag     900596 non-null  float64\n",
      " 22  T2M_binned_medium      900596 non-null  object \n",
      " 23  T2M_binned_high        900596 non-null  object \n",
      " 24  RH2M_binned_medium     900596 non-null  object \n",
      " 25  RH2M_binned_high       900596 non-null  object \n",
      " 26  acq_date               906078 non-null  object \n",
      " 27  geometry               906078 non-null  object \n",
      " 28  predicted_area_km2     906078 non-null  float64\n",
      "dtypes: float64(23), object(6)\n",
      "memory usage: 200.5+ MB\n"
     ]
    }
   ],
   "source": [
    "wildfire = pd.read_csv(\"./USA data/merged_fire.csv\")\n",
    "wildfire.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스피어만 상관관계 분석 결과 (결측값 제거 후):\n",
      "--------------------------------------------------\n",
      "상관관계 계수 0.064, p-value 0.0000 : (latitude)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 -0.011, p-value 0.0000 : (longitude)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 0.813, p-value 0.0000 : (brightness)는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\n",
      "상관관계 계수 0.640, p-value 0.0000 : (bright_t31)는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\n",
      "상관관계 계수 1.000, p-value 0.0000 : (frp)는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\n",
      "상관관계 계수 0.154, p-value 0.0000 : (T2M)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 -0.026, p-value 0.0000 : (WS2M)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 -0.198, p-value 0.0000 : (RH2M)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 -0.073, p-value 0.0000 : (PRECTOTCORR)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 0.339, p-value 0.0000 : (confidence_h)는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\n",
      "상관관계 계수 0.202, p-value 0.0000 : (confidence_l)는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\n",
      "상관관계 계수 -0.404, p-value 0.0000 : (confidence_n)는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\n",
      "상관관계 계수 0.601, p-value 0.0000 : (daynight_D)는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\n",
      "상관관계 계수 -0.601, p-value 0.0000 : (daynight_N)는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\n",
      "상관관계 계수 -0.003, p-value 0.0094 : (year)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 0.027, p-value 0.0000 : (month)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 -0.032, p-value 0.0000 : (day)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 0.051, p-value 0.0000 : (season)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 -0.035, p-value 0.0000 : (weekday)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 -0.146, p-value 0.0000 : (WS2M_RH2M_interaction)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 0.024, p-value 0.0000 : (high_temperature)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "상관관계 계수 -0.022, p-value 0.0000 : (precipitation_flag)는 predicted_area_km2에 대해 약한 상관관계 (유의미)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 병합 하며 결측치가 생겨 결측값 제거\n",
    "wildfire = wildfire.dropna()\n",
    "\n",
    "# 독립 변수(X): float64 타입만 추출, predicted_area_km2 제외\n",
    "numeric_columns = wildfire.select_dtypes(include=['float64']).columns\n",
    "X = wildfire[numeric_columns.drop('predicted_area_km2')]\n",
    "y = wildfire['predicted_area_km2']\n",
    "\n",
    "# 스피어만 상관계수 계산\n",
    "print(\"스피어만 상관관계 분석 결과 (결측값 제거 후):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for value in X.columns:\n",
    "    statistic, pvalue = spearmanr(X[value], y)\n",
    "    \n",
    "    # 출력\n",
    "    if pvalue < 0.05 and abs(statistic) >= 0.2:\n",
    "        print(f\"상관관계 계수 {statistic:.3f}, p-value {pvalue:.4f} : ({value})는 predicted_area_km2에 대해 유의미하다 (강한 상관관계)\")\n",
    "    elif pvalue < 0.05:\n",
    "        print(f\"상관관계 계수 {statistic:.3f}, p-value {pvalue:.4f} : ({value})는 predicted_area_km2에 대해 약한 상관관계 (유의미)\")\n",
    "    else:\n",
    "        print(f\"상관관계 계수 {statistic:.3f}, p-value {pvalue:.4f} : ({value})는 predicted_area_km2에 대해 유의미하지 않다\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(543646, 22) (543646,)\n",
      "(181216, 22) (181216,)\n",
      "(181216, 22) (181216,)\n"
     ]
    }
   ],
   "source": [
    "train_cols = [\n",
    "    \"frp\",           # 강한 상관관계\n",
    "    \"brightness\",    # 강한 상관관계\n",
    "    \"bright_t31\",    # 강한 상관관계\n",
    "    \"confidence_h\",  # 강한 상관관계\n",
    "    \"confidence_l\",  # 강한 상관관계\n",
    "    \"confidence_n\",  # 강한 상관관계\n",
    "    \"daynight_D\",    # 강한 상관관계\n",
    "    \"daynight_N\",    # 강한 상관관계\n",
    "    \"latitude\",      # 약한 상관관계\n",
    "    \"longitude\",     # 약한 상관관계\n",
    "    \"T2M\",           # 약한 상관관계\n",
    "    \"WS2M\",          # 약한 상관관계\n",
    "    \"RH2M\",          # 약한 상관관계\n",
    "    \"PRECTOTCORR\",   # 약한 상관관계\n",
    "    \"year\",          # 약한 상관관계\n",
    "    \"month\",         # 약한 상관관계\n",
    "    \"day\",           # 약한 상관관계\n",
    "    \"season\",        # 약한 상관관계\n",
    "    \"weekday\",       # 약한 상관관계\n",
    "    \"WS2M_RH2M_interaction\",  # 약한 상관관계\n",
    "    \"high_temperature\",       # 약한 상관관계\n",
    "    \"precipitation_flag\"      # 약한 상관관계\n",
    "]\n",
    "\n",
    "# 데이터 준비\n",
    "train = wildfire[train_cols]\n",
    "target = wildfire[\"predicted_area_km2\"]\n",
    "\n",
    "# 첫 번째 분할 (훈련 데이터와 검증 데이터)\n",
    "train_input, val_input, train_target, val_target = train_test_split(train, target, test_size=0.4, random_state=42, shuffle=True)\n",
    "\n",
    "# 두 번째 분할 (검증 데이터와 테스트 데이터)\n",
    "val_input, test_input, val_target, test_target = train_test_split(val_input, val_target, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "print(train_input.shape, train_target.shape)\n",
    "print(val_input.shape, val_target.shape)\n",
    "print(test_input.shape, test_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.9999999997156066, val_score: 0.9999999978892833, test_score: 0.9999999981095657, 과적합여부: 1.8263233148019253e-09\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor() \n",
    "\n",
    "rf.fit(train_input, train_target)\n",
    "\n",
    "train_score = rf.score(train_input, train_target)\n",
    "val_score = rf.score(val_input, val_target)\n",
    "test_score = rf.score(test_input, test_target)\n",
    "\n",
    "print(f\"train_score: {train_score}, val_score: {val_score}, test_score: {test_score}, 과적합여부: {train_score - val_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning and training RandomForest with None...\n",
      "Best Parameters for RandomForest: {'n_estimators': 200, 'min_samples_split': 10, 'max_depth': 20}\n",
      "-*** RandomForest with None ***-\n",
      "훈련: 0.9982, 검증: 0.9948, 테스트: 0.9955, 과적합여부: 0.0034\n",
      "사용 가능한 모델입니다 (일반화).\n",
      "\n",
      "Saved RandomForest with None as final model.\n",
      "Tuning and training HistGradientBoosting with None...\n",
      "Best Parameters for HistGradientBoosting: {'max_iter': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "-*** HistGradientBoosting with None ***-\n",
      "훈련: 0.9947, 검증: 0.9939, 테스트: 0.9947, 과적합여부: 0.0008\n",
      "사용 가능한 모델입니다 (일반화).\n",
      "\n",
      "Saved HistGradientBoosting with None as final model.\n",
      "Tuning and training XGB with None...\n",
      "Best Parameters for XGB: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "-*** XGB with None ***-\n",
      "훈련: 0.9948, 검증: 0.9940, 테스트: 0.9947, 과적합여부: 0.0008\n",
      "사용 가능한 모델입니다 (일반화).\n",
      "\n",
      "Saved XGB with None as final model.\n",
      "Tuning and training RandomForest with Standard...\n"
     ]
    }
   ],
   "source": [
    "models = Models()\n",
    "models.total_models(train_input, train_target, val_input, val_target, test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = models.get_results()\n",
    "print(results_df)\n",
    "results_df.to_csv(\"model_results_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 실행\n",
    "models = Models()\n",
    "models.total_models(train_input, train_target, val_input, val_target, test_input, test_target)\n",
    "results_df = models.get_results()\n",
    "print(results_df)\n",
    "results_df.to_csv(\"model_results_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 실행\n",
    "models = Models()\n",
    "models.total_models(train_input, train_target, val_input, val_target, test_input, test_target)\n",
    "results_df = models.get_results()\n",
    "print(results_df)\n",
    "results_df.to_csv(\"model_results_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pk_dl_202503_kernel",
   "language": "python",
   "name": "pk_dl_202503"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
